<?xml version="1.0" encoding="UTF-8"?>
<testng-results skipped="0" failed="0" ignored="15" total="22" passed="7">
  <reporter-output>
  </reporter-output>
  <suite name="rbac" duration-ms="5094" started-at="2022-06-21T09:19:23Z" finished-at="2022-06-21T09:19:28Z">
    <groups>
    </groups>
    <test name="rbac" duration-ms="5094" started-at="2022-06-21T09:19:23Z" finished-at="2022-06-21T09:19:28Z">
      <class name="com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup">
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup@4fcd19b3]" name="setup" is-config="true" duration-ms="328" started-at="2022-06-21T17:19:27Z" finished-at="2022-06-21T17:19:27Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup@4fcd19b3]" name="test" duration-ms="141" started-at="2022-06-21T17:19:27Z" finished-at="2022-06-21T17:19:27Z">
          <exception class="java.sql.SQLException">
            <message>
              <![CDATA[org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.sdgggsdgat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.sdgggsdgat org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:177)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 more]]>
            </message>
            <full-stacktrace>
              <![CDATA[java.sql.SQLException: org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.sdgggsdgat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.sdgggsdgat org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:177)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 moreat org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:385)at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:254)at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:476)at com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup.test(NoSelectOnTableByGroup.java:38)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)at org.testng.internal.Invoker.invokeMethod(Invoker.java:571)at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:707)at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:979)at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)at org.testng.TestRunner.privateRun(TestRunner.java:648)at org.testng.TestRunner.run(TestRunner.java:505)at org.testng.SuiteRunner.runTest(SuiteRunner.java:455)at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)at org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)at org.testng.SuiteRunner.run(SuiteRunner.java:364)at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)at org.testng.TestNG.runSuitesSequentially(TestNG.java:1187)at org.testng.TestNG.runSuitesLocally(TestNG.java:1116)at org.testng.TestNG.runSuites(TestNG.java:1028)at org.testng.TestNG.run(TestNG.java:996)at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:178)at org.apache.maven.surefire.testng.TestNGXmlTestSuite.execute(TestNGXmlTestSuite.java:92)at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:96)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)]]>
            </full-stacktrace>
          </exception> <!-- java.sql.SQLException -->
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup@4fcd19b3]" name="tearDown" is-config="true" duration-ms="140" started-at="2022-06-21T17:19:27Z" finished-at="2022-06-21T17:19:28Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
      </class> <!-- com.sequoiadp.rbac.ddl.NoSelectOnTableByGroup -->
      <class name="com.sequoiadp.rbac.ddl.NoSelectOnTable">
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTable@5204062d]" name="setup" is-config="true" duration-ms="297" started-at="2022-06-21T17:19:26Z" finished-at="2022-06-21T17:19:27Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTable@5204062d]" name="test" duration-ms="110" started-at="2022-06-21T17:19:27Z" finished-at="2022-06-21T17:19:27Z">
          <exception class="java.sql.SQLException">
            <message>
              <![CDATA[org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.njuty0j7at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.njuty0j7at org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:177)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 more]]>
            </message>
            <full-stacktrace>
              <![CDATA[java.sql.SQLException: org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.njuty0j7at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have select privilege on table testdb.njuty0j7at org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:177)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 moreat org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:385)at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:254)at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:476)at com.sequoiadp.rbac.ddl.NoSelectOnTable.test(NoSelectOnTable.java:32)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)at org.testng.internal.Invoker.invokeMethod(Invoker.java:571)at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:707)at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:979)at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)at org.testng.TestRunner.privateRun(TestRunner.java:648)at org.testng.TestRunner.run(TestRunner.java:505)at org.testng.SuiteRunner.runTest(SuiteRunner.java:455)at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)at org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)at org.testng.SuiteRunner.run(SuiteRunner.java:364)at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)at org.testng.TestNG.runSuitesSequentially(TestNG.java:1187)at org.testng.TestNG.runSuitesLocally(TestNG.java:1116)at org.testng.TestNG.runSuites(TestNG.java:1028)at org.testng.TestNG.run(TestNG.java:996)at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:178)at org.apache.maven.surefire.testng.TestNGXmlTestSuite.execute(TestNGXmlTestSuite.java:92)at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:96)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)]]>
            </full-stacktrace>
          </exception> <!-- java.sql.SQLException -->
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.NoSelectOnTable@5204062d]" name="tearDown" is-config="true" duration-ms="109" started-at="2022-06-21T17:19:27Z" finished-at="2022-06-21T17:19:27Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
      </class> <!-- com.sequoiadp.rbac.ddl.NoSelectOnTable -->
      <class name="com.sequoiadp.rbac.ddl.WithoutUsage">
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.WithoutUsage@376b4233]" name="setup" is-config="true" duration-ms="313" started-at="2022-06-21T17:19:28Z" finished-at="2022-06-21T17:19:28Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.WithoutUsage@376b4233]" name="test" duration-ms="156" started-at="2022-06-21T17:19:28Z" finished-at="2022-06-21T17:19:28Z">
          <exception class="java.sql.SQLException">
            <message>
              <![CDATA[org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have USAGE privilege on database testdbat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have USAGE privilege on database testdbat org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:170)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 more]]>
            </message>
            <full-stacktrace>
              <![CDATA[java.sql.SQLException: org.apache.hive.service.cli.HiveSQLException: Error running query: org.apache.spark.sql.AnalysisException: user sdbadmin does not have USAGE privilege on database testdbat org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:361)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.$anonfun$run$2(SparkExecuteStatementOperation.scala:263)at scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties(SparkOperation.scala:78)at org.apache.spark.sql.hive.thriftserver.SparkOperation.withLocalProperties$(SparkOperation.scala:62)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.withLocalProperties(SparkExecuteStatementOperation.scala:43)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:263)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2$$anon$3.run(SparkExecuteStatementOperation.scala:258)at java.security.AccessController.doPrivileged(Native Method)at javax.security.auth.Subject.doAs(Subject.java:422)at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1730)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation$$anon$2.run(SparkExecuteStatementOperation.scala:272)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.run(FutureTask.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)at java.lang.Thread.run(Thread.java:748)Caused by: org.apache.spark.sql.AnalysisException: user sdbadmin does not have USAGE privilege on database testdbat org.apache.spark.sql.execution.AuthorityCheck.checkAuth(AuthorityCheck.scala:170)at org.apache.spark.sql.execution.AuthorityCheck.checkTableAuth(AuthorityCheck.scala:72)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:201)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.checkSelectStatement(AuthorityCheck.scala:216)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3(AuthorityCheck.scala:269)at org.apache.spark.sql.execution.AuthorityCheck.$anonfun$apply$3$adapted(AuthorityCheck.scala:251)at org.apache.spark.sql.catalyst.trees.TreeNode.foreach(TreeNode.scala:174)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:251)at org.apache.spark.sql.execution.AuthorityCheck.apply(AuthorityCheck.scala:39)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:216)at scala.collection.LinearSeqOptimized.foldLeft(LinearSeqOptimized.scala:126)at scala.collection.LinearSeqOptimized.foldLeft$(LinearSeqOptimized.scala:122)at scala.collection.immutable.List.foldLeft(List.scala:89)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:213)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:205)at scala.collection.immutable.List.foreach(List.scala:392)at org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:205)at org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:196)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:190)at org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:155)at org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)at org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:183)at org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:174)at org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:228)at org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:173)at org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:73)at org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)at org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:143)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:143)at org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:73)at org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:71)at org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:63)at org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:101)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:99)at org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:619)at org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:776)at org.apache.spark.sql.SparkSession.sql(SparkSession.scala:614)at org.apache.spark.sql.SQLContext.sql(SQLContext.scala:650)at org.apache.spark.sql.hive.thriftserver.SparkExecuteStatementOperation.org$apache$spark$sql$hive$thriftserver$SparkExecuteStatementOperation$$execute(SparkExecuteStatementOperation.scala:325)... 16 moreat org.apache.hive.jdbc.HiveStatement.waitForOperationToComplete(HiveStatement.java:385)at org.apache.hive.jdbc.HiveStatement.execute(HiveStatement.java:254)at org.apache.hive.jdbc.HiveStatement.executeQuery(HiveStatement.java:476)at com.sequoiadp.rbac.ddl.WithoutUsage.test(WithoutUsage.java:41)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.testng.internal.MethodInvocationHelper.invokeMethod(MethodInvocationHelper.java:124)at org.testng.internal.Invoker.invokeMethod(Invoker.java:571)at org.testng.internal.Invoker.invokeTestMethod(Invoker.java:707)at org.testng.internal.Invoker.invokeTestMethods(Invoker.java:979)at org.testng.internal.TestMethodWorker.invokeTestMethods(TestMethodWorker.java:125)at org.testng.internal.TestMethodWorker.run(TestMethodWorker.java:109)at org.testng.TestRunner.privateRun(TestRunner.java:648)at org.testng.TestRunner.run(TestRunner.java:505)at org.testng.SuiteRunner.runTest(SuiteRunner.java:455)at org.testng.SuiteRunner.runSequentially(SuiteRunner.java:450)at org.testng.SuiteRunner.privateRun(SuiteRunner.java:415)at org.testng.SuiteRunner.run(SuiteRunner.java:364)at org.testng.SuiteRunnerWorker.runSuite(SuiteRunnerWorker.java:52)at org.testng.SuiteRunnerWorker.run(SuiteRunnerWorker.java:84)at org.testng.TestNG.runSuitesSequentially(TestNG.java:1187)at org.testng.TestNG.runSuitesLocally(TestNG.java:1116)at org.testng.TestNG.runSuites(TestNG.java:1028)at org.testng.TestNG.run(TestNG.java:996)at org.apache.maven.surefire.testng.TestNGExecutor.run(TestNGExecutor.java:178)at org.apache.maven.surefire.testng.TestNGXmlTestSuite.execute(TestNGXmlTestSuite.java:92)at org.apache.maven.surefire.testng.TestNGProvider.invoke(TestNGProvider.java:96)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:498)at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)]]>
            </full-stacktrace>
          </exception> <!-- java.sql.SQLException -->
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.WithoutUsage@376b4233]" name="tearDown" is-config="true" duration-ms="94" started-at="2022-06-21T17:19:28Z" finished-at="2022-06-21T17:19:28Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
      </class> <!-- com.sequoiadp.rbac.ddl.WithoutUsage -->
      <class name="com.sequoiadp.rbac.ddl.GrantModify">
        <test-method status="PASS" signature="initSuite(java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String, java.lang.String)[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="initSuite" is-config="true" duration-ms="15" started-at="2022-06-21T17:19:23Z" finished-at="2022-06-21T17:19:23Z">
          <params>
            <param index="0">
              <value>
                <![CDATA[192.168.16.75]]>
              </value>
            </param>
            <param index="1">
              <value>
                <![CDATA[10000]]>
              </value>
            </param>
            <param index="2">
              <value>
                <![CDATA[sequoiadb]]>
              </value>
            </param>
            <param index="3">
              <value>
                <![CDATA[123456]]>
              </value>
            </param>
            <param index="4">
              <value>
                <![CDATA[sdbadmin]]>
              </value>
            </param>
            <param index="5">
              <value>
                <![CDATA[sdbadmin]]>
              </value>
            </param>
            <param index="6">
              <value>
                <![CDATA[testdb]]>
              </value>
            </param>
            <param index="7">
              <value>
                <![CDATA[testgroup]]>
              </value>
            </param>
          </params>
          <reporter-output>
          </reporter-output>
        </test-method> <!-- initSuite -->
        <test-method status="PASS" signature="cleanandbuild()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="cleanandbuild" is-config="true" duration-ms="1078" started-at="2022-06-21T17:19:23Z" finished-at="2022-06-21T17:19:24Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- cleanandbuild -->
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="setup" is-config="true" duration-ms="297" started-at="2022-06-21T17:19:24Z" finished-at="2022-06-21T17:19:25Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="test" duration-ms="344" started-at="2022-06-21T17:19:25Z" finished-at="2022-06-21T17:19:25Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="tearDown" is-config="true" duration-ms="109" started-at="2022-06-21T17:19:25Z" finished-at="2022-06-21T17:19:25Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
        <test-method status="PASS" signature="recycle()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantModify@27d415d9]" name="recycle" is-config="true" duration-ms="78" started-at="2022-06-21T17:19:28Z" finished-at="2022-06-21T17:19:28Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- recycle -->
      </class> <!-- com.sequoiadp.rbac.ddl.GrantModify -->
      <class name="com.sequoiadp.rbac.ddl.Groupselect">
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.Groupselect@5579bb86]" name="setup" is-config="true" duration-ms="359" started-at="2022-06-21T17:19:26Z" finished-at="2022-06-21T17:19:26Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.Groupselect@5579bb86]" name="test" duration-ms="203" started-at="2022-06-21T17:19:26Z" finished-at="2022-06-21T17:19:26Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.Groupselect@5579bb86]" name="tearDown" is-config="true" duration-ms="125" started-at="2022-06-21T17:19:26Z" finished-at="2022-06-21T17:19:26Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
      </class> <!-- com.sequoiadp.rbac.ddl.Groupselect -->
      <class name="com.sequoiadp.rbac.ddl.GrantSelect">
        <test-method status="PASS" signature="setup()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantSelect@31f924f5]" name="setup" is-config="true" duration-ms="297" started-at="2022-06-21T17:19:25Z" finished-at="2022-06-21T17:19:25Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- setup -->
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantSelect@31f924f5]" name="test" duration-ms="203" started-at="2022-06-21T17:19:25Z" finished-at="2022-06-21T17:19:26Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
        <test-method status="PASS" signature="tearDown()[pri:0, instance:com.sequoiadp.rbac.ddl.GrantSelect@31f924f5]" name="tearDown" is-config="true" duration-ms="94" started-at="2022-06-21T17:19:26Z" finished-at="2022-06-21T17:19:26Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- tearDown -->
      </class> <!-- com.sequoiadp.rbac.ddl.GrantSelect -->
      <class name="com.sequoiadp.rbac.ddl.CreateDatabase123">
        <test-method status="PASS" signature="test()[pri:0, instance:com.sequoiadp.rbac.ddl.CreateDatabase123@5c18298f]" name="test" duration-ms="187" started-at="2022-06-21T17:19:24Z" finished-at="2022-06-21T17:19:24Z">
          <reporter-output>
          </reporter-output>
        </test-method> <!-- test -->
      </class> <!-- com.sequoiadp.rbac.ddl.CreateDatabase123 -->
    </test> <!-- rbac -->
  </suite> <!-- rbac -->
</testng-results>
